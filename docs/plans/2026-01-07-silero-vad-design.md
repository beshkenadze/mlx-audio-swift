# Silero VAD for MLX-Swift â€” Design Document

**Date:** 2026-01-07  
**Status:** Approved  
**Module:** `MLXAudio/SileroVAD/`

---

## Overview

Voice Activity Detection (VAD) module for mlx-audio-swift, porting Silero VAD to Apple's MLX framework. Provides real-time speech detection with both streaming and batch processing APIs.

### Goals
- Silero Python API compatibility (`getSpeechTimestamps`)
- Real-time streaming with <5ms latency per chunk
- iOS/macOS support on Apple Silicon
- Thread-safe, composable architecture

### Non-Goals
- Audio capture (user provides MLXArray)
- Resampling (user provides 16kHz audio)
- Speaker diarization

---

## Performance Requirements

| Metric | Target |
|--------|--------|
| Latency per chunk | <5ms (M1), <3ms (M2+) |
| Memory footprint | <5MB |
| Model size | ~1.2MB (safetensors) |
| Accuracy (F1) | â‰¥0.95 |

---

## Audio Format Contract

```swift
public enum VADAudioFormat {
    public static let sampleRate: Int = 16000
    public static let chunkSamples: Int = 512      // 32ms
    public static let chunkDuration: TimeInterval = 0.032
    public static let valueRange: ClosedRange<Float> = -1.0...1.0
    public static let dtype: DType = .float32
}
```

---

## Module Structure

```
MLXAudio/
â””â”€â”€ SileroVAD/
    â”œâ”€â”€ Models/
    â”‚   â”œâ”€â”€ VADModel.swift         # Neural network (stateless)
    â”‚   â”œâ”€â”€ VADConfig.swift        # Configuration + presets
    â”‚   â””â”€â”€ VADState.swift         # LSTM state container
    â”œâ”€â”€ Core/
    â”‚   â”œâ”€â”€ VADIterator.swift      # Stateful chunk processor
    â”‚   â”œâ”€â”€ SpeechDetector.swift   # Event detection (composable)
    â”‚   â””â”€â”€ SpeechTimestamps.swift # Batch segment detection
    â”œâ”€â”€ Processing/
    â”‚   â””â”€â”€ STFT.swift             # Short-time Fourier transform
    â”œâ”€â”€ Errors/
    â”‚   â””â”€â”€ VADError.swift         # Comprehensive error types
    â””â”€â”€ VADSession.swift           # Public API entry point
```

---

## Public API

### VADSession (Thread-Safe Entry Point)

```swift
/// Thread-safe factory and convenience methods.
/// Create once, use from any thread.
public final class VADSession: Sendable {
    public static let sampleRate: Int = 16000
    
    /// Load model with bundled weights
    public static func make() async throws -> VADSession
    
    /// Load from custom weights path
    public static func make(weightsURL: URL) async throws -> VADSession
    
    /// Create independent iterator for streaming
    public func makeIterator(config: VADConfig = .default) -> VADIterator
    
    /// Batch processing convenience
    public func getSpeechTimestamps(
        _ audio: MLXArray,
        config: VADConfig = .default
    ) throws -> [SpeechSegment]
}
```

### VADIterator (Stateful Processing â€” NOT Thread-Safe)

```swift
/// Processes audio chunks with persistent LSTM state.
/// Must be used from single thread/task.
public final class VADIterator {
    /// Process single chunk, returns probability + speech flag
    public func process(_ audio: MLXArray) throws -> VADResult
    
    /// Current position in audio stream
    public var currentTimestamp: TimeInterval { get }
    
    /// Reset state for new audio stream
    public func reset()
}
```

### SpeechDetector (Composable Event Detection)

```swift
/// Detects speech start/end events from probability stream.
/// Separate from VADIterator for composition flexibility.
public final class SpeechDetector {
    public init(config: VADConfig = .default)
    
    /// Feed result, get optional event
    public func feed(_ result: VADResult) -> SpeechEvent?
    
    public func reset()
}

public enum SpeechEvent: Sendable {
    case speechStarted(at: TimeInterval)
    case speechEnded(at: TimeInterval, duration: TimeInterval)
    case speechDiscarded(reason: DiscardReason)
}
```

### Configuration

```swift
public struct VADConfig: Sendable, Equatable {
    public var threshold: Float = 0.5
    public var minSpeechDurationMs: Int = 250
    public var minSilenceDurationMs: Int = 100
    public var speechPadMs: Int = 30
    
    /// Balanced for general use
    public static let `default` = VADConfig()
    
    /// Lower threshold, catches more speech
    /// Use: quiet speakers, recording, transcription
    public static let sensitive = VADConfig(
        threshold: 0.35,
        minSpeechDurationMs: 200,
        minSilenceDurationMs: 150,
        speechPadMs: 50
    )
    
    /// Higher threshold, fewer false positives  
    /// Use: noisy environments, voice commands
    public static let strict = VADConfig(
        threshold: 0.65,
        minSpeechDurationMs: 300,
        minSilenceDurationMs: 80,
        speechPadMs: 20
    )
    
    /// Quick response for voice assistants
    public static let conversation = VADConfig(
        threshold: 0.5,
        minSpeechDurationMs: 200,
        minSilenceDurationMs: 50,
        speechPadMs: 30
    )
}
```

### Output Types

```swift
public struct VADResult: Sendable, Equatable {
    public let probability: Float      // 0.0 - 1.0
    public let isSpeech: Bool          // probability >= threshold
    public let timestamp: TimeInterval // position in stream
}

public struct SpeechSegment: Sendable, Equatable {
    public let start: TimeInterval     // padding applied
    public let end: TimeInterval       // padding applied
    public var duration: TimeInterval { end - start }
}
```

---

## Error Handling

```swift
public enum VADError: LocalizedError, Sendable {
    // Initialization
    case weightsNotFound(path: String)
    case weightsCorrupted(reason: String)
    case modelInitializationFailed(underlying: Error)
    
    // Audio format
    case invalidSampleRate(expected: Int, got: Int)
    case invalidChunkSize(expected: Int, got: Int)
    case invalidAudioShape(expected: String, got: [Int])
    case invalidDtype(expected: DType, got: DType)
    case audioOutOfRange(min: Float, max: Float)
    
    // Runtime
    case processingFailed(reason: String)
    case stateCorrupted
}
```

---

## Thread Safety Model

| Type | Thread-Safe | Sendable |
|------|-------------|----------|
| `VADSession` | âœ… Yes | âœ… Yes |
| `VADIterator` | âŒ No | âŒ No |
| `SpeechDetector` | âŒ No | âŒ No |
| `VADConfig` | âœ… Yes (immutable) | âœ… Yes |
| `VADResult` | âœ… Yes (immutable) | âœ… Yes |
| `SpeechSegment` | âœ… Yes (immutable) | âœ… Yes |

**Rule:** One `VADIterator` per Task. Create multiple iterators for concurrent streams.

---

## Neural Network Architecture

```
Audio (512 samples @ 16kHz)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STFT                           â”‚
â”‚  basis: (258, 1, 256)           â”‚
â”‚  â†’ 129 frequency bins           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Encoder (4Ã— Conv1d + ReLU)     â”‚
â”‚  Conv1d(129 â†’ 128, k=3)         â”‚
â”‚  Conv1d(128 â†’  64, k=3, s=2)    â”‚
â”‚  Conv1d( 64 â†’  64, k=3, s=2)    â”‚
â”‚  Conv1d( 64 â†’ 128, k=3)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LSTM (hidden=128)              â”‚
â”‚  Stateful across chunks         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Output Conv1d(128 â†’ 1) + Ïƒ     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
  Probability [0.0 - 1.0]
```

**Weights:** `Resources/silero_vad_16k.safetensors` (~1.2MB, 309K params)

---

## Usage Examples

### Batch Processing

```swift
let vad = try await VADSession.make()
let audio: MLXArray = loadAudio("speech.wav")  // 16kHz, Float32, [-1,1]

let segments = try vad.getSpeechTimestamps(audio)

for segment in segments {
    print("Speech: \(segment.start)s - \(segment.end)s")
}
```

### Real-Time Streaming

```swift
let vad = try await VADSession.make()
let iterator = vad.makeIterator(config: .sensitive)
let detector = SpeechDetector(config: .sensitive)

for chunk in audioChunks {
    let result = try iterator.process(chunk)
    
    if let event = detector.feed(result) {
        switch event {
        case .speechStarted(let time):
            print("ğŸ¤ Speech started at \(time)s")
        case .speechEnded(let time, let duration):
            print("ğŸ”‡ Speech ended, duration: \(duration)s")
        case .speechDiscarded:
            break
        }
    }
}
```

### Multiple Concurrent Streams

```swift
let vad = try await VADSession.make()

Task {
    let iter1 = vad.makeIterator()
    for chunk in stream1 { try iter1.process(chunk) }
}

Task {
    let iter2 = vad.makeIterator()
    for chunk in stream2 { try iter2.process(chunk) }
}
```

---

## Edge Case Behaviors

| Scenario | Behavior |
|----------|----------|
| Speech < minSpeechDuration | Filtered, returns empty |
| Pause < minSilenceDuration | Treated as continuous speech |
| Probability = threshold | Classified as speech (>=) |
| Silent audio | Empty array, no error |
| Audio out of [-1,1] range | Throws `audioOutOfRange` |
| Speech at audio start | Segment.start = 0.0 (no negative) |
| Speech cut off at end | Segment captured to audio end |

---

## Implementation Checklist

- [ ] `VADModel.swift` â€” Neural network layers
- [ ] `STFT.swift` â€” Spectrogram transform
- [ ] `VADState.swift` â€” LSTM state container
- [ ] `VADIterator.swift` â€” Stateful processor
- [ ] `SpeechDetector.swift` â€” Event detection
- [ ] `SpeechTimestamps.swift` â€” Batch segment detection
- [ ] `VADSession.swift` â€” Public API + weight loading
- [ ] `VADConfig.swift` â€” Configuration presets
- [ ] `VADError.swift` â€” Error types
- [ ] Bundle `silero_vad_16k.safetensors` in Resources
- [ ] Unit tests for edge cases
- [ ] Integration tests with real audio

---

## Expert Review Summary

**Reviewed by:** Wiegers, Adzic, Fowler, Nygard

| Dimension | Score | Notes |
|-----------|-------|-------|
| Requirements Clarity | 9/10 | NFRs added |
| Architecture | 9/10 | SRP applied |
| Testability | 8/10 | Edge cases documented |
| Production Readiness | 8/10 | Error handling complete |
| **Overall** | **8.5/10** | Ready for implementation |

---

## Next Steps

1. Implement `VADModel.swift` with weight loading
2. Implement `STFT.swift` matching Silero's transform
3. Build `VADIterator` with state management
4. Add `SpeechDetector` for event composition
5. Create `VADSession` public API
6. Write unit tests from edge case specifications
7. Integration test with real audio samples
